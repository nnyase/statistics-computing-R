---
title: "Practical 16 Optimization"
author: "Ndivhuwo Nyase"
date: "2023-02-13"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)

library(tidyverse)
library(gvlma)
library(broom)
library(corrplot)
theme_set(theme_classic())
```

## Question 1

```{r question 1a}

tobacco <- read.delim("~/Desktop/statistics-computing-R/datasets/tobacco.txt")
head(tobacco)
summary(tobacco)
```


```{r summary plot}
par(cex = 0.8)
plot(x= 0,
     xlab = 'Explantory Variables',
     ylab = 'burn rate',
     main = 'Graph showing the relationship between burn and other variables.',
     pch=19,type = 'b', xlim = c(0,max(tobacco$sugar)), ylim = c(1,3))
  
# Adding scatterplot of sugar
points(tobacco$sugar, y =tobacco$burn, col='red', pch=19)
  
# Adding scatterplot of nicotine
points(tobacco$nicotine, y= tobacco$burn ,col='darkblue', pch=19)
  
# Adding scatterplot of nitrogen
points(tobacco$nitrogen,y =tobacco$burn, col='orange', pch=19)
  
# Adding scatterplot of chlorine
points(tobacco$chlorine,y =tobacco$burn, col='purple', pch=19)
  
# Adding scatterplot of potas
points(tobacco$potas,y =tobacco$burn, col='black', pch=19)

# phospho
points(tobacco$phospho,y =tobacco$burn, col='lightgreen', pch=19)
  
# Adding scatterplot of calcuim
points(tobacco$calcium,y =tobacco$burn, col='pink', pch=19)

points(tobacco$magnes,y =tobacco$burn, col = 'yellow', pch = 19)
  
legend('topright',legend=c('Sugar','Nicotine','Nitrogen',
                          'Chlorine','Potas', 'Phospho', 'calcuim', 'magnes'), pch=c(19, 19), 
       col=c('red','blue','orange','purple','black', 'lightgreen', 'pink', 'yellow'), title = 'Legend')
  
```


```{r correlation_plot}
burn_corr <- cor(tobacco$burn,tobacco)
burn_corr
corrplot(burn_corr)
```

The correlation suggests there is a strong relationship with potasium and chlorine.

+ burn rate and % ***chlorine: -0.6234392***
* burn rate and % ***potassium: 0.4865503***

&nbsp;
&nbsp;

## Question 1b 
#Fit a simple linear regression model using lm() and print the model output. Choose the most pertinent explanatory variable to model the response variable, providing a motivation for your choice from the output in (a).

```{r q1b }

model1b <- lm(burn ~ sugar + chlorine + nicotine + potas + nitrogen + calcium + phospho + magnes,data = tobacco)
summary(model1b)
```
We will use chlorine as it is significant at a 1% level which is the highest significant score compared to the other variables suggesting that it plays a bigger effect than the other variables. In addition to this, it had the highest correlation than the other variables.

```{r burn and chlorine}
model_burn_chl <- lm(burn ~ chlorine,data = tobacco)
summary(model_burn_chl)
plot(x = 0,                 
     xlab = "chlorine", 
     ylab = "Burn",
     xlim = c(0, 5), 
     ylim = c(1,3),
     main = "linear regression model of burn and chlorine")

points(x = tobacco$chlorine, y = tobacco$burn, col = "blue" , pch = 20)
abline(model_burn_chl, col="darkblue", lty=2)

```

## Question 1c

```{r q1c }

sumSqMin <- function(par, data) {
  with(data, sum((par[1] + par[2] * y + par[3] * x - z)^2))
}


library(dplyr)

data <- tobacco %>%
  select(burn, chlorine)
data
min_residuals <- function(data, par) {
                   with(data, sum((par[1] + par[2] * burn - chlorine)^2))
}

#find coefficients of linear regression model
optim(par=c(0, 1), fn=min_residuals, data=data)

```
# Question 1d

```{r q1d }

loglikelihood = function(beta,x,y){
  s <- beta[1]
  intercept <- beta[2]
  slope <- beta[3]
  fitted_values <- x*slope + intercept
  residual <- y - fitted_values

  n <- length(y)
  SSE <- sum(residual^2)
  ll = - 0.5*n*log(2*pi) - 0.5*n*log(s^2) - 0.5*1/(s^2)*SSE  
  return(-ll)
}

fit <- optim(par=c(0.5,10,10), fn=loglikelihood, x = tobacco$chlorine, y = tobacco$burn, method="L-BFGS-B", lower=c(0.0001,-Inf,-Inf))
fit
```

The loglikehood agrees with the above linear regression.

&nbsp;
&nbsp;
&nbsp;

## Question 2 

Using output from Part 1, fit a simple linear model using the most appropriate predictor. Take note of the correlation between the response variable and the fitted values of the regression. The square of this amount is known as the coefficient of determination (‘Multiple R-squared’ or simply 𝑅2). Explain what this quantity represents and why a larger 𝑅2 is preferred. Use the summary output and take note of the 𝑅2 amount. Comment on the significance of the beta parameters and whether regression analysis should be undertaken on this data.

```{r Q2A }
burn_chl <- lm(burn ~ chlorine, data = data)
summary(burn_chl)
```
R^2 also known as coefficient of determination, R-squared is the proportion of the variation in dependent variable that can be explained by the independent variables. We want this to be large as we want our dependent variable to be explained by the independent variable as much as we can so we can define or determine the relationships between variables. In the case of the above model, it represents the proportion of variation of the response (burn) in relation to the chlorine.

A linear regression model was conducted to examine the dependent variable burn and the relationship with independent variable chlorine. We found a significant relationship (p < 0.001) between burn and chlorine (R2 = 0.3887). In this model the equattion for burn is burn = 2.11 + -(0.17*chlorine) ± 0.045. Because the p value is so low (p =0.00087), we can reject the null hypothesis and conclude that chlorine has a statistically significant effect on burn. With that being said, to improve the regression analysis we must include the other variables that may have relationship with burn included in the dataset. 


For question 2b, we will add the explantory variable one at a time to examine the impact of each variable. Starting with 

# Question 2b

```{r q2 b}

# add magnes
burn_chl_mag <- lm(burn ~ chlorine + magnes , data = tobacco)
summary(burn_chl_mag)
#add phospho
burn_chl_mag_pho <- lm(burn ~ chlorine + magnes + phospho, data = tobacco)
summary(burn_chl_mag_pho)
#add potas
burn_chl_mag_pho_pota <- lm(burn ~ chlorine + magnes + phospho + potas, data = tobacco)
summary(burn_chl_mag_pho_pota)
#add calcuim
burn_chl_mag_pho_pota_others <- lm(burn ~ chlorine + magnes + phospho + potas+ calcium, data = tobacco)
summary(burn_chl_mag_pho_pota_others)
# add nitrogen
burn_chl_mag_pho_pota_others <- lm(burn ~ chlorine + magnes + phospho + potas+ calcium+ nitrogen, data = tobacco)
summary(burn_chl_mag_pho_pota_others)
# add nicotine
burn_chl_mag_pho_pota_others <- lm(burn ~ chlorine + magnes + phospho + potas+ calcium+  nitrogen + nicotine, data = tobacco)
summary(burn_chl_mag_pho_pota_others)
#add sugar == FULL MODEL
full_model <- lm(burn ~ chlorine + magnes + phospho + potas+ calcium+  nitrogen + nicotine + sugar, data = tobacco)
summary(burn_chl_mag_pho_pota_others)
```

# Question 2c

A multivariable linear regression model was conducted to examine the relationship between burn and all exaplantory variables in the dataset. Chlorine is the only statistical significant variable at a significance of 1%. Additionally, sugar and nitrogen suggest they have a insignificant and small relationship with the response variable burn as both have p-values > 0.8 and small estimate scores. 

With that being said, A linear model without sugar and nitrogen is what we will go with due to the small beta coefficents and high p-values suggesting they do not have a relationship with the burn time. 

# Question 2d

```{r q 2d }

model <- lm(burn ~ chlorine + magnes + phospho + potas+ calcium + nicotine, data = tobacco)
summary(model) 
boxplot(model[['residuals']],main='Boxplot: Residuals',ylab='residual value')
confint(model)

```

## Checking Assumptions
```{r assumpitons}
par(mfrow = c(2, 2))
plot(model)


```
&nbsp;
&nbsp;

# Linearity

Linearity: In plot 1,1, there is no pattern in the residual plot and it is more or less centred around mean 0. This suggests that we can assume linear relationship between the predictors and the response variable. 

# Homogenity 
The scale-location plot shows the residuals are spread equally along the ranges of predictors as it is a horizontal line with equally spread points. This suggests constant variances in residual errors or homogenity.

# Normality of residuals
The normal probability plot of residuals approximates a straight line thus agreeing with the normality of residuals.

# Outliers
Residuals vs Leverage: The plot above highlights the top 3 most extreme points (#24, #2 and #10), with a standardized residuals below -2. However, there is no outliers that exceed 3 standard deviations, what is good.

```{r}
# This package runs the shapiro and the Wilcox test for testing the assumptions
gvlma(model)
```

# Question 3
```{r 3: Beetles}
days <- c(0, 8, 2, 41, 63, 79, 97, 117, 135, 154)
beetles <- c(2, 47, 192, 256, 768, 896, 1120, 896, 1184, 1024)


logistic <- function(N0, r, K, d, b) {
  b - K*N0 / (N0 + (K - N0)*exp(-r*d))
}

sse <- function(params, d, b) {
  err <- logistic(params[1], params[2], params[3], d, b)
  sum(err^2)
}

fit<- nlm(sse, c(N0=2, r=1, K=1), d=days, b=beetles, hessian = TRUE)
fit

```